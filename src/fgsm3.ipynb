{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = \"lenet_mnist_model.pth\" #事前学習済みMNISTモデル(重みパラメータ)\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LeNet Model 定義\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) #畳み込み層nn.Conv2d(入力のチャネル数, 出力のチャネル数，カーネルの1辺のサイズ)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d() #過学習を防ぐためにいくつかのノードを無効にする\n",
    "        self.fc1 = nn.Linear(320, 50) #全結合層nn.Linear(入力のサイズ(20channel×4height×4width), 出力サイズ) height, weightについては計算して事前に出す\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2)) #活性化関数Relu, Maxプーリング\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320) #サイズを調整x.view(-1, 指定するサイズ)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# MNISTのTest datasetと dataloaderの定義\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            ])), \n",
    "        batch_size=1, shuffle=False)\n",
    "\n",
    "# 使うデバイス（CPUかGPUか）の定義\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "# ネットワークの初期化\n",
    "model = Net().to(device)\n",
    "\n",
    "# 訓練済みモデルのロード\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "# モデルを評価モードに設定。本チュートリアルの例では、これはドロップアウト層等を評価モードにするのに必要\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM による攻撃用のコード\n",
    "def fgsm_attack(image,  data_grad):\n",
    "    # # データの勾配の各要素のsign値を取得します\n",
    "    # sign_data_grad = data_grad.sign()\n",
    "    # # 入力画像の各ピクセルを調整して、ノイズが追加された画像を作成します\n",
    "    # perturbed_image = image + 0.1*sign_data_grad\n",
    "    # # [0,1]の範囲になるようデータをクリップします\n",
    "    # perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # # ノイズが追加された画像を返します\n",
    "    return image\n",
    "    # return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(image, data_grad):\n",
    "    data_grad_sum = 0\n",
    "    for i in data_grad[0][0]:\n",
    "        for j in i:\n",
    "            data_grad_sum += j\n",
    "    \n",
    "    data_grad_avg = data_grad_sum / (28 * 28)\n",
    "    perturbed_image = image + (data_grad > data_grad_avg * 10).float() - (data_grad < -data_grad_avg * 10).float()\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(image, data_grad):\n",
    "    data_grad_sort = []\n",
    "    for i in data_grad[0][0]:\n",
    "        for j in i:\n",
    "            data_grad_sort.append(j)\n",
    "    data_grad_sort.sort()\n",
    "    threshold_p = data_grad_sort[5]\n",
    "    threshold_n = data_grad_sort[778]\n",
    "    perturbed_image = image + (data_grad > threshold_p).float() - (data_grad < threshold_n).float()\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test( model, device, test_loader):\n",
    "\n",
    "    # 精度カウンター\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    # テスト用データセット内の全てのサンプルをループします\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        # データとラベルをデバイス（CPUもしくはGPU）に送信します\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # テンソルの requires_grad 属性を設定します。攻撃者にとっては重要な設定です。\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # データをモデルに順伝播させます\n",
    "        output = model(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # 最大の確率のインデックスを取得します。\n",
    "\n",
    "        # 最初から予測が間違っている場合、攻撃する必要がないため次のイテレーションに進みます。\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # 損失を計算します\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # 既存の勾配を全てゼロにします\n",
    "        model.zero_grad()\n",
    "\n",
    "        # 逆伝播させてモデルの勾配を計算します\n",
    "        loss.backward()\n",
    "\n",
    "        # データの勾配を取得します\n",
    "        data_grad = data.grad.data\n",
    "        \n",
    "        # FGSMによる攻撃の関数を呼び出します\n",
    "        perturbed_data = fgsm_attack(data, data_grad)\n",
    "\n",
    "        # ノイズ付き画像を再度分類します\n",
    "        output = model(perturbed_data)\n",
    "\n",
    "        # 攻撃の成功を確認します\n",
    "        final_pred = output.max(1, keepdim=True)[1] # log-probabilityが最大のインデックスを取得します\n",
    "\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "\n",
    "\n",
    "    # epsilonごとの最終的な精度を算出\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Test Accuracy = {} / {} = {}\".format(correct, len(test_loader), final_acc))\n",
    "\n",
    "    # 精度と敵対的サンプルを返却\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 9810 / 10000 = 0.981\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# 各epsilonごとにテストを実行\n",
    "acc, ex = test(model, device, test_loader)\n",
    "accuracies.append(acc)\n",
    "examples.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x720 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnt = 0\n",
    "plt.figure(figsize=(8,10))\n",
    "\n",
    "for j in range(len(examples[0])):\n",
    "    cnt += 1\n",
    "    plt.subplot(1,len(examples[0]),cnt)\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    orig,adv,ex = examples[0][j]\n",
    "    plt.title(\"{} -> {}\".format(orig, adv))\n",
    "    plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
